---
title: Data Pipeline Example
description: Complete ETL pipeline with better-py
---

# Data Pipeline Example

Build a complete ETL pipeline using better-py.

## Overview

This example shows how to build a data processing pipeline with error handling and validation.

## Code

```python
from better_py import Result, PersistentList

def extract(source: str) -> Result[list[dict], str]:
    """Extract data from source"""
    try:
        data = read_csv(source)
        return Result.ok(data)
    except Exception as e:
        return Result.error(f"Extract failed: {e}")

def transform(data: list[dict]) -> Result[list[dict], str]:
    """Transform data"""
    return Result.ok([
        {**row, "processed": True}
        for row in data
    ])

def load(data: list[dict], dest: str) -> Result[None, str]:
    """Load data to destination"""
    try:
        write_csv(dest, data)
        return Result.ok(None)
    except Exception as e:
        return Result.error(f"Load failed: {e}")

def pipeline(source: str, dest: str) -> Result[None, str]:
    """Complete ETL pipeline"""
    return (
        extract(source)
        .bind(transform)
        .bind(lambda data: load(data, dest))
    )
```

## See Also

- [Error Handling Guide](/docs/guides/error-handling)
- [Data Processing Guide](/docs/guides/data-processing)
